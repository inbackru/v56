#!/usr/bin/env python3
"""
–ü–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∞ —Å–∞–π—Ç–∞ –¥–ª—è InBack.ru
–°–æ–∑–¥–∞–µ—Ç XML sitemap —Å–æ –≤—Å–µ–º–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏ –≤–∫–ª—é—á–∞—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –º–∞—Ä—à—Ä—É—Ç—ã
"""

import os
import json
import sqlite3
from datetime import datetime
from flask import Flask, url_for
from app import app, db
from models import ExcelProperty, ResidentialComplex
from sqlalchemy import text

def get_real_data():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã"""
    data = {
        'properties': [],
        'complexes': [],
        'developers': [],
        'streets': []
    }
    
    with app.app_context():
        try:
            # –û–±—ä–µ–∫—Ç—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ (–ø–µ—Ä–≤—ã–µ 100 –¥–ª—è sitemap)
            properties = db.session.execute(
                text("SELECT property_id FROM excel_properties WHERE property_id IS NOT NULL ORDER BY property_id LIMIT 100")
            ).fetchall()
            data['properties'] = [str(row[0]) for row in properties if row[0]]
            
            # –ñ–∏–ª—ã–µ –∫–æ–º–ø–ª–µ–∫—Å—ã
            complexes = db.session.execute(
                text("SELECT id, slug FROM residential_complexes WHERE id IS NOT NULL")
            ).fetchall()
            data['complexes'] = [(str(row[0]), row[1]) for row in complexes if row[0]]
            
            # –ó–∞—Å—Ç—Ä–æ–π—â–∏–∫–∏ (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ)
            developers = db.session.execute(
                text("SELECT DISTINCT developer_name FROM excel_properties WHERE developer_name IS NOT NULL AND developer_name != '' ORDER BY developer_name")
            ).fetchall()
            data['developers'] = [row[0] for row in developers if row[0]]
            
        except Exception as e:
            print(f"Error getting database data: {e}")
    
    # –£–ª–∏—Ü—ã –∏–∑ JSON
    try:
        with open('data/streets.json', 'r', encoding='utf-8') as f:
            streets_data = json.load(f)
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 200 —É–ª–∏—Ü –¥–ª—è sitemap
            data['streets'] = [street['name'] for street in streets_data[:200] if street.get('name')]
    except Exception as e:
        print(f"Error loading streets: {e}")
    
    return data

# –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
STATIC_ROUTES = {
    # –ì–ª–∞–≤–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã - –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
    'index': {'priority': '1.0', 'changefreq': 'daily'},
    'properties': {'priority': '0.9', 'changefreq': 'daily'},
    'residential_complexes': {'priority': '0.9', 'changefreq': 'daily'},
    'developers': {'priority': '0.8', 'changefreq': 'weekly'},
    'map_view': {'priority': '0.8', 'changefreq': 'weekly'},
    
    # –û –∫–æ–º–ø–∞–Ω–∏–∏
    'about': {'priority': '0.8', 'changefreq': 'monthly'},
    'how_it_works': {'priority': '0.8', 'changefreq': 'monthly'},
    'reviews': {'priority': '0.7', 'changefreq': 'weekly'},
    'contacts': {'priority': '0.7', 'changefreq': 'monthly'},
    'security': {'priority': '0.6', 'changefreq': 'monthly'},
    'careers': {'priority': '0.5', 'changefreq': 'monthly'},
    
    # –ö–æ–Ω—Ç–µ–Ω—Ç
    'blog': {'priority': '0.8', 'changefreq': 'daily'},
    'news': {'priority': '0.7', 'changefreq': 'daily'},
    'streets': {'priority': '0.7', 'changefreq': 'weekly'},
    'districts': {'priority': '0.7', 'changefreq': 'weekly'},
    
    # –ò–ø–æ—Ç–µ–∫–∞
    'ipoteka': {'priority': '0.8', 'changefreq': 'weekly'},
    'family_mortgage': {'priority': '0.7', 'changefreq': 'monthly'},
    'it_mortgage': {'priority': '0.7', 'changefreq': 'monthly'},
    'military_mortgage': {'priority': '0.7', 'changefreq': 'monthly'},
    'developer_mortgage': {'priority': '0.7', 'changefreq': 'monthly'},
    'maternal_capital': {'priority': '0.7', 'changefreq': 'monthly'},
    
    # –°–µ—Ä–≤–∏—Å–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    'comparison': {'priority': '0.6', 'changefreq': 'weekly'},
    'complex_comparison': {'priority': '0.6', 'changefreq': 'weekly'},
    'favorites': {'priority': '0.5', 'changefreq': 'daily'},
    'thank_you': {'priority': '0.3', 'changefreq': 'yearly'},
    
    # –ü–æ–ª–∏—Ç–∏–∫–∏
    'privacy_policy': {'priority': '0.3', 'changefreq': 'yearly'},
    'data_processing_consent': {'priority': '0.3', 'changefreq': 'yearly'}
}

# –†–∞–π–æ–Ω—ã –ö—Ä–∞—Å–Ω–æ–¥–∞—Ä–∞ —Å SEO-–∏–º–µ–Ω–∞–º–∏
DISTRICTS = [
    'tsentralnyy', 'zapadny', 'karasunsky', 'festivalny', 'gidrostroitelei', 
    'yubileynyy', 'pashkovsky', 'prikubansky', 'enka', 'solnechny', 
    'panorama', 'vavilova', 'yablonovskiy', 'uchhoz-kuban', 'dubinka',
    'komsomolsky', 'kolosistiy', 'kozhzavod', 'kubansky', 'krasnodarskiy',
    '9i-kilometr', 'aviagorodok', 'avrora', 'basket-hall', 'berezovy',
    'cheremushki', 'gorkhutor', 'hbk', 'kalinino', 'kkb', 'ksk', 
    'krasnaya-ploshad', '40-let-pobedy', 'tsiolkovskogo', 'stasova',
    'kalinovaya', 'kotliarevskogo', 'akademika-lukianenko', 'starokorsunskaya',
    'im-40-letiya-pobedy', 'rossiyskaya', 'turgenevsky', 'slavyansky',
    'novorossiysky', 'tbilissky', 'severo-kavkazsky', 'adygeysky',
    'prochorzhsky', 'kievsky', 'dneprovskiy', 'moldavsky', 'sovetsky',
    'universitetsky', 'industrialny', 'shevchenko'
]

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–ª–æ–≥–∞
BLOG_CATEGORIES = ['cashback', 'districts', 'mortgage', 'market', 'legal', 'tips']

def generate_sitemap():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π XML –∫–∞—Ä—Ç—ã —Å–∞–π—Ç–∞"""
    
    print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∫–∞—Ä—Ç—ã —Å–∞–π—Ç–∞...")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    data = get_real_data()
    print(f"üìä –î–∞–Ω–Ω—ã–µ: {len(data['properties'])} –æ–±—ä–µ–∫—Ç–æ–≤, {len(data['complexes'])} –ñ–ö, {len(data['developers'])} –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤, {len(data['streets'])} —É–ª–∏—Ü")
    
    sitemap_xml = '''<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.sitemaps.org/schemas/sitemap/0.9
        http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd">
'''

    base_url = "https://inback.ru"
    today = datetime.now().strftime('%Y-%m-%d')
    url_count = 0
    
    with app.app_context():
        # 1. –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        print("üìÑ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü...")
        for route, config in STATIC_ROUTES.items():
            try:
                url = url_for(route)
                sitemap_xml += f'''  <url>
    <loc>{base_url}{url}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>{config['changefreq']}</changefreq>
    <priority>{config['priority']}</priority>
  </url>
'''
                url_count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞—Ä—à—Ä—É—Ç {route}: {e}")
        
        # 2. –û–±—ä–µ–∫—Ç—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
        print("üè† –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏...")
        for property_id in data['properties']:
            try:
                url = url_for('property_detail', property_id=int(property_id))
                sitemap_xml += f'''  <url>
    <loc>{base_url}{url}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.8</priority>
  </url>
'''
                url_count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—ä–µ–∫—Ç {property_id}: {e}")
        
        # 3. –ñ–∏–ª—ã–µ –∫–æ–º–ø–ª–µ–∫—Å—ã
        print("üè¢ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∂–∏–ª—ã—Ö –∫–æ–º–ø–ª–µ–∫—Å–æ–≤...")
        for complex_id, slug in data['complexes']:
            try:
                # –û—Å–Ω–æ–≤–Ω–æ–π –º–∞—Ä—à—Ä—É—Ç
                url = url_for('residential_complex_detail', complex_id=int(complex_id))
                sitemap_xml += f'''  <url>
    <loc>{base_url}{url}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.8</priority>
  </url>
'''
                url_count += 1
                
                # SEO –º–∞—Ä—à—Ä—É—Ç –µ—Å–ª–∏ –µ—Å—Ç—å slug
                if slug:
                    sitemap_xml += f'''  <url>
    <loc>{base_url}/zk/{slug}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.8</priority>
  </url>
'''
                    url_count += 1
                    
            except Exception as e:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ñ–ö {complex_id}: {e}")
        
        # 4. –ó–∞—Å—Ç—Ä–æ–π—â–∏–∫–∏
        print("üèóÔ∏è –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤...")
        for i, developer in enumerate(data['developers'], 1):
            try:
                url = url_for('developer_detail', developer_id=i)
                sitemap_xml += f'''  <url>
    <loc>{base_url}{url}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.7</priority>
  </url>
'''
                url_count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞ {developer}: {e}")
        
        # 5. –†–∞–π–æ–Ω—ã
        print("üìç –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–π–æ–Ω–æ–≤...")
        for district in DISTRICTS:
            try:
                url = f"/districts/{district}"
                sitemap_xml += f'''  <url>
    <loc>{base_url}{url}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.7</priority>
  </url>
'''
                url_count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–∞–π–æ–Ω {district}: {e}")
        
        # 6. –£–ª–∏—Ü—ã (–ø–µ—Ä–≤—ã–µ 200)
        print("üõ£Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–ª–∏—Ü...")
        for street_name in data['streets']:
            try:
                # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π URL –¥–ª—è —É–ª–∏—Ü—ã
                street_url = street_name.lower().replace(' ', '-').replace('(', '').replace(')', '').replace('/', '-')
                url = f"/streets/{street_url}"
                sitemap_xml += f'''  <url>
    <loc>{base_url}{url}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.6</priority>
  </url>
'''
                url_count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–ª–∏—Ü—É {street_name}: {e}")
        
        # 7. –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–ª–æ–≥–∞
        print("üìù –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –±–ª–æ–≥–∞...")
        for category in BLOG_CATEGORIES:
            try:
                url = url_for('blog_category', category_slug=category)
                sitemap_xml += f'''  <url>
    <loc>{base_url}{url}</loc>
    <lastmod>{today}</lastmod>
    <changefreq>daily</changefreq>
    <priority>0.7</priority>
  </url>
'''
                url_count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –±–ª–æ–≥–∞ {category}: {e}")
    
    sitemap_xml += '</urlset>'
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
    os.makedirs('static', exist_ok=True)
    with open('static/sitemap.xml', 'w', encoding='utf-8') as f:
        f.write(sitemap_xml)
    
    print(f"‚úÖ –ö–∞—Ä—Ç–∞ —Å–∞–π—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞! –í—Å–µ–≥–æ URL: {url_count}")
    print(f"üìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: static/sitemap.xml")
    print(f"üåê –î–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: {base_url}/sitemap.xml")
    
    return sitemap_xml

def update_robots_txt():
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ robots.txt —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –Ω–∞ sitemap"""
    
    robots_content = f"""User-agent: *
Allow: /

# –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è –±–æ—Ç–æ–≤
Disallow: /admin/
Disallow: /manager/
Disallow: /api/
Disallow: /uploads/
Disallow: /static/
Disallow: /login
Disallow: /logout
Disallow: *.pdf$
Disallow: /*?*

# –í—Ä–µ–º—è –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
Crawl-delay: 1

# –ö–∞—Ä—Ç–∞ —Å–∞–π—Ç–∞
Sitemap: https://inback.ru/sitemap.xml

# –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –±–æ—Ç–æ–≤
User-agent: Googlebot
Crawl-delay: 1

User-agent: Yandex
Crawl-delay: 1

User-agent: Bingbot  
Crawl-delay: 2
"""
    
    with open('static/robots.txt', 'w', encoding='utf-8') as f:
        f.write(robots_content)
    
    print("ü§ñ robots.txt –æ–±–Ω–æ–≤–ª–µ–Ω")

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Ä—Ç—ã —Å–∞–π—Ç–∞ InBack.ru")
    generate_sitemap()
    update_robots_txt()
    print("‚úÖ –ì–æ—Ç–æ–≤–æ! –ö–∞—Ä—Ç–∞ —Å–∞–π—Ç–∞ –∏ robots.txt —Å–æ–∑–¥–∞–Ω—ã")
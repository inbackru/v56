#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–µ—Ä —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Selenium –≤–º–µ—Å—Ç–æ Botasaurus
"""

import logging
import time
import re
from typing import List, Dict
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

def create_stable_driver():
    """–°–æ–∑–¥–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω—ã–π Selenium –¥—Ä–∞–π–≤–µ—Ä"""
    try:
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-images')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(20)
        return driver
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
        return None

def scrape_developers_simple(url: str = None) -> Dict:
    """–ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤ —Å domclick.ru"""
    if not url:
        url = 'https://krasnodar.domclick.ru/zastroishchiki'
    
    driver = None
    try:
        logger.info(f"üåê –û—Ç–∫—Ä—ã–≤–∞–µ–º {url}")
        
        driver = create_stable_driver()
        if not driver:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –±—Ä–∞—É–∑–µ—Ä")
        
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
        driver.get(url)
        
        # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏
        time.sleep(5)
        
        # –ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–æ–ª–ª
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
        time.sleep(2)
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)
        
        # –ü–æ–ª—É—á–∞–µ–º HTML
        html = driver.page_source
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω HTML —Ä–∞–∑–º–µ—Ä–æ–º {len(html)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü–∞—Ä—Å–∏–º –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤
        developers = parse_developers_from_html_simple(html)
        
        return {
            'success': True,
            'developers': developers,
            'html_size': len(html),
            'url': url
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        return {
            'success': False,
            'error': str(e),
            'developers': [],
            'url': url
        }
    finally:
        if driver:
            try:
                driver.quit()
                logger.info("üîª –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
            except:
                pass

def parse_developers_from_html_simple(html: str) -> List[Dict]:
    """–ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤ –∏–∑ HTML"""
    try:
        soup = BeautifulSoup(html, 'html.parser')
        developers = []
        
        # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞–º–∏
        table_rows = soup.find_all('tr')
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(table_rows)} —Å—Ç—Ä–æ–∫ –≤ HTML")
        
        for row in table_rows:
            try:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 4:  # –ú–∏–Ω–∏–º—É–º 4 –∫–æ–ª–æ–Ω–∫–∏
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —è—á–µ–µ–∫
                    name_text = cells[0].get_text(strip=True)
                    completed_text = cells[1].get_text(strip=True) if len(cells) > 1 else '0'
                    under_construction_text = cells[2].get_text(strip=True) if len(cells) > 2 else '0'
                    on_time_text = cells[3].get_text(strip=True) if len(cells) > 3 else '0%'
                    contact_text = cells[4].get_text(strip=True) if len(cells) > 4 else ''
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
                    if name_text and len(name_text) > 2 and name_text not in ['–ó–∞—Å—Ç—Ä–æ–π—â–∏–∫', '–ù–∞–∑–≤–∞–Ω–∏–µ', '–ö–æ–º–ø–∞–Ω–∏—è']:
                        
                        # –ü–∞—Ä—Å–∏–º —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                        completed_match = re.search(r'(\d+)', completed_text)
                        under_construction_match = re.search(r'(\d+)', under_construction_text)
                        on_time_match = re.search(r'(\d+)', on_time_text)
                        
                        completed_buildings = int(completed_match.group(1)) if completed_match else 0
                        under_construction = int(under_construction_match.group(1)) if under_construction_match else 0
                        on_time_percentage = int(on_time_match.group(1)) if on_time_match else 100
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω
                        phone_match = re.search(r'\+7\s?\(?\d{3}\)?\s?\d{3}-?\d{2}-?\d{2}', contact_text)
                        phone = phone_match.group(0) if phone_match else ''
                        
                        developer_data = {
                            'name': name_text,
                            'completed_buildings': completed_buildings,
                            'under_construction': under_construction,
                            'on_time_percentage': on_time_percentage,
                            'phone': phone,
                            'source': 'domclick_simple',
                            'specialization': '–ñ–∏–ª–∏—â–Ω–æ–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ',
                            'description': f'–ó–∞—Å—Ç—Ä–æ–π—â–∏–∫ {name_text} - —Å–¥–∞–Ω–æ –¥–æ–º–æ–≤: {completed_buildings}, —Å—Ç—Ä–æ–∏—Ç—Å—è: {under_construction}, –≤–æ–≤—Ä–µ–º—è: {on_time_percentage}%'
                        }
                        
                        developers.append(developer_data)
                        logger.info(f"  ‚úÖ {name_text} - —Å–¥–∞–Ω–æ: {completed_buildings}, —Å—Ç—Ä–æ–∏—Ç—Å—è: {under_construction}")
                        
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏: {e}")
                continue
        
        # –ï—Å–ª–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É
        if not developers:
            logger.info("–ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
            text_content = soup.get_text()
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–π
            company_patterns = [
                r'[–ê-–Ø]{2,}[–∞-—è]*\s*(?:–°—Ç—Ä–æ–π|–î–µ–≤–µ–ª–æ–ø–º–µ–Ω—Ç|–ò–Ω–≤–µ—Å—Ç|–ì—Ä—É–ø–ø|–ì–ö)',
                r'–û–û–û\s+["\¬´]?[–ê-–Ø][–∞-—è\s]+["\¬ª]?',
                r'[–ê-–Ø][–∞-—è]+\s+[–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø][–∞-—è]+)?'
            ]
            
            for pattern in company_patterns:
                matches = re.findall(pattern, text_content)
                for match in matches:
                    if len(match) > 3 and not any(d['name'] == match.strip() for d in developers):
                        developers.append({
                            'name': match.strip(),
                            'source': 'text_extraction',
                            'specialization': '–ñ–∏–ª–∏—â–Ω–æ–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ',
                            'description': f'–ó–∞—Å—Ç—Ä–æ–π—â–∏–∫ {match} –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã'
                        })
        
        logger.info(f"–ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤: {len(developers)}")
        return developers
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML: {e}")
        return []

if __name__ == "__main__":
    # –¢–µ—Å—Ç –ø–∞—Ä—Å–µ—Ä–∞
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞...")
    
    result = scrape_developers_simple()
    
    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: success={result['success']}")
    if result['success']:
        print(f"üè¢ –ù–∞–π–¥–µ–Ω–æ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤: {len(result['developers'])}")
        for dev in result['developers'][:5]:
            print(f"  - {dev['name']}")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")